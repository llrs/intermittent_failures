---
title: "Packages intermittent failtures"
author: "Llu√≠s Revilla Sancho"
date: "`r Sys.Date()`"
output: 
  html_document:
    fig_caption: true
    code_folding: hide
    self_contained: false
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", 
                      message = FALSE, warning = FALSE,
                      collapse = TRUE, cache = FALSE)
```


# Introduction

This report checks if the status of packages on CRAN are due to intermittent failures.

Failures defined as warnings, notes or errors without change on:

 - R version used (if not stable the same svn snapshot)

 - The package version (Note that CRAN might modify a package without changing the version)

 - Their dependencies

Reasons of these failures might be because the packages depend on:

 - Random generation numbers

 - Flacky external resources

 - Other ?

Why is this important?

Because package maintainers of dependencies of that package, R core and CRAN team need to check if the failures are false positives.

This report started because it was [suggested as something that the R-repositories working group](https://github.com/RConsortium/r-repositories-wg/issues/7) could help the CRAN team.


# Retrieve data

It makes use of [tools::CRAN_check_results](https://search.r-project.org/R/refmans/tools/html/CRANtools.html) to retrieve the data.

```{r save}
library("dplyr")
library("tools", include.only = c("package_dependencies", "CRAN_check_results"))
library("flextable", include.only = c("flextable", "autofit"))
# Use a LOCAL environment to check if files can be overwritten on my computer
local_build <- as.logical(Sys.getenv("LOCAL", "FALSE"))
yc <- readRDS("today.RDS")
tc <- CRAN_check_results()
if (!interactive() && !local_build) {
  message("Saving today's file.")
  saveRDS(tc, file = "today.RDS")
} 
```

The checks are from multiple flavors release, devel, old release and patched on multiple machines and configurations.

```{r flavors-today, fig.cap="Machine configurations and flavors being tested on CRAN."}
old_flavors <- readRDS("flavors.RDS")
flavors <- unique(tc$Flavor)
proto <- data.frame(r_version = character(),
                    os = character(),
                    architecture = character(),
                    other = character())
flavors_df <- strcapture(
  pattern = "r-([[:alnum:]]+)-([[:alnum:]]+)-([[:alnum:]_\\+]+)-?(.*)", 
  x = flavors,
  proto = proto)

# Extract R version used and svn id
h <- "https://www.r-project.org/nosvn/R.check/%s/A3-00check.html"
links <- sprintf(h, flavors)
extract_revision <- function(x) {
  r <- readLines(x, 12)[12]
  version <- strcapture(pattern = "([[:digit:]]\\.[[:digit:]]\\.[[:digit:]])",  
                        x = r, proto = data.frame(version = character()))
  revision <- strcapture(pattern = "(r[[:digit:]]+)",  x = r,
             proto = data.frame(revision = character()))
  cbind(version, revision)
}
revision <- data.frame(version = character(),
                      revision = character())
for (i in links) {
  revision <- rbind(revision, extract_revision(i))
}

flavors_df <- cbind(flavors = flavors, flavors_df, revision)
if (!interactive() && !local_build) {
  saveRDS(flavors_df, "flavors.RDS")
}

m <- match(tc$Flavor, flavors_df$flavors)
tc_flavors <- cbind(tc, flavors_df[m, ])
flextable(flavors_df) |> 
  autofit()
```


It assumes that the same configuration in one package is used for all.
Or in other words that the reports of the configuration (svn revision and version) for the A3 package is the same as for all the other packages.

Warning: This assumption is not always true, but this would require to check each log file on each flavor to verify the R and svn id of each package (which could take too much time and resources).

# Overview

Briefly an introduction of how much effort goes into checking

```{r plots-install, fig.alt="Machines (y axis) vs install time (seconds, x axis), violing plot usually around 10 seconds.", fig.cap="Distribution of install time on each machine."}
library("ggplot2")
theme_set(theme_minimal())
tc |> 
  filter(!is.na(T_install)) |> 
  ggplot() +
  geom_violin(aes(T_install, Flavor)) +
  scale_x_log10() +
  labs(x = "seconds", title = "Time to install", y = element_blank())
```

This means that just to install all the packages on the multiple flavors with a single CPU would take `r round(sum(tc$T_install, na.rm = TRUE)/(60*60*24))` days.

```{r plots-check, fig.alt="Machines (y axis) vs check time (seconds, x axis), violing plot usually around 100 seconds.", fig.cap="Distribution of checking time on each machine."}
tc |> 
  filter(!is.na(T_check)) |> 
  ggplot() +
  geom_violin(aes(T_check, Flavor), trim = FALSE) +
  scale_x_log10() +
  labs(x = "seconds", title = "Time to check", y = element_blank())
```

This means that to check all the packages on the multiple flavors with a single CPU would take `r round(sum(tc$T_check, na.rm = TRUE)/(60*60*24))` days.

```{r plots-total, fig.alt="Machines (y axis) vs total time (seconds, x axis), violing plot usually around 100 seconds.", fig.cap="Distribution of total time on each machine."}
tc |> 
  filter(!is.na(T_total)) |> 
  ggplot() +
  geom_violin(aes(T_total, Flavor)) +
  scale_x_log10() +
  labs(x = "seconds", title = "Time to check and install", y = element_blank())
```

This means that to install and check all the packages with a single CPU would take `r round(sum(tc$T_total, na.rm = TRUE)/(60*60*24))` days.

I don't know the computational cost of 266 days of CPU (every day), but a rough calculation of 2.5 cents per hour means `r round(sum(tc$T_total, na.rm = TRUE)/(60*60)*0.025, 2)` dollars daily dedicated to this.

```{r package-versions, fig.cap="Number of version of each packages tested."}
tc |> 
  group_by(Package) |> 
  summarize(Versions = n_distinct(Version)) |> 
  ungroup() |> 
  count(Versions, name = "Packages", sort = TRUE) |> 
  flextable() |> 
  autofit()
```

This was surprising, but sometimes checks have multiple versions. 
Probably when a new version is added and the system don't catch it for a certain machine. 

```{r packages-flavors, fig.cap="Number of machines each package is tested."}
tc |> 
  group_by(Package) |> 
  summarize(Flavors = n_distinct(Flavor)) |> 
  ungroup() |> 
  count(Flavors, name = "Packages", sort = TRUE) |> 
  flextable() |> 
  autofit()
```

Similarly, often packages are only tested on few configurations.

Combining both we can have packages with few configurations that have multiple versions being tested.

```{r plot-versions-flavors, fig.alt="Flavors of machines and versions of packages", fig.cap="Most packages are just tested one version."}
tc |> 
  group_by(Package) |> 
  summarize(Versions = as.character(n_distinct(Version)),
            Flavors = n_distinct(Flavor)) |> 
  ungroup() |> 
  count(Flavors, Versions, name = "Packages") |> 
  ggplot() +
  geom_tile(aes(Flavors, Versions, fill = log10(Packages))) +
  scale_x_continuous(expand = expansion())
  
```

But focusing on those that have just one version of the package being tested, most of the machines have packages either OK or with some notes.

```{r plot-flavors-status, fig.alt="On the vertical axis the machine, on the horitzonal axis the packages colored by the status.", fig.cap="Most frequent status is OK or NOTE on all machines."}
man_colors <- c("OK" = "green", "NOTE" = "darkgreen", 
                "WARNING" = "yellow", "ERROR" = "red", "FAILURE" = "black")
tc |> 
  group_by(Package) |> 
  filter(n_distinct(Version) == 1) |> 
  ungroup() |> 
  group_by(Flavor) |> 
  count(Status, name = "packages") |> 
  mutate(perc = packages/sum(packages),
         Status = forcats::fct_relevel(Status, names(man_colors))) |> 
  ggplot() + 
  geom_col(aes(perc, Flavor, fill = Status)) +
  scale_x_continuous(expand = expansion(), labels = scales::percent_format()) +
  scale_fill_manual(values = man_colors) +
  labs(title = "Packages check status", x = element_blank())
```

If we look at the most frequent status report for packages we can see this table:

```{r table-packages-status, fig.cap="Table with the most frequent status of packages."}
ts <- tc |> 
  group_by(Package) |> 
  filter(n_distinct(Version) == 1) |> 
  count(Status, name = "flavors") |> 
  ungroup() |> 
  tidyr::pivot_wider(values_from = flavors, names_from = Status, 
                     values_fill = 0) |> 
  count(OK, NOTE, WARNING, ERROR, FAILURE, name = "packages", sort = TRUE)
download.file("https://cran.r-project.org/web/packages/packages.rds", 
              destfile = "packages.RDS") # From the help page
ap <- readRDS("packages.RDS") |> 
  as.data.frame() |> 
  distinct(Package, .keep_all = TRUE)
ap_bioc <- available.packages(repos = BiocManager::repositories()[1:5])
ap_bioc <- cbind(ap_bioc, Additional_repositories = NA)
ap_colm <- intersect(colnames(ap), colnames(ap_bioc))
ap <- rbind(ap[, ap_colm], ap_bioc[, ap_colm])
head(ts) |> 
  flextable() |> 
  autofit()
```

We can see that the most common occurrences are some sort of OK and notes on checks. We can also check the [official results on CRAN](https://cran.r-project.org/web/checks/check_summary.html).

We can see that `r scales::percent(ts$packages[ts$OK == length(flavors)]/nrow(ap), accuracy = 0.01)` of packages pass all checks without notes.

Now let's see which of the notes or failures are due to intermittent issues.

# Compare

First we need to make sure that we compare the right configurations.
They must be the same machine, the same R version and the same svn revision between yesterday and today.

```{r versions}
# Compare the previous flavor with today's
m_flavor <- which(flavors_df$flavors %in% old_flavors$flavors)
m_version <- which(flavors_df$version %in% old_flavors$version)
m_revision <- which(flavors_df$revision %in% old_flavors$revision)
tm <- table(c(m_flavor, m_version, m_revision))
compare <- flavors_df$flavors[tm == 3] # Only missing the packages version
```



## All changes

Next, compare the status of the packages if the version of the package is the same.


```{r packages-possible}
#| fig.cap = "Packages with different status"
# Find package on the flavors to compare that haven't changed versions
library("dplyr")
tcc <- filter(tc, Flavor %in% compare) |> 
  select(Flavor, Package, Version, Status) |> 
  arrange(Flavor, Package)
ycc <- filter(yc, Flavor %in% compare) |> 
  select(Flavor, Package, Version, Status) |> 
  arrange(Flavor, Package)

all_checks <- merge(tcc, ycc, by = c("Flavor", "Package"), 
                    suffixes = c(".t", ".y"), all = TRUE) 

possible_packages <- all_checks |> 
  filter(Version.t == Version.y & # Same version
           Status.t != Status.y & # Different status
           !is.na(Status.y) & # No new version or removed package
           !is.na(Status.t)) |> 
  rename(Today = Status.t, Yesterday = Status.y)
possible_packages |> 
  select(Package, Flavor, Today, Yesterday, -Version.t, -Version.y) |> 
  arrange(Package, Flavor) |> 
  flextable() |> 
  autofit()
```

If the machine and R versions is the same but the check of the package is different there might be some discrepancy between the dependencies.

```{r packages-dependencies, eval=length(unique(possible_packages$Package)) < 1000}
  # Extract dependencies
  dependencies <- package_dependencies(unique(possible_packages$Package),
                                       # Should it check all the recursive dependencies or only direct?
                                       db = ap, # Only considering those dependencies on CRAN and Bioconductor but not any Additional_repositories. 
                                       recursive = TRUE, 
                                       which = c("Depends", "Imports", "LinkingTo", "Suggests"))
  
  # Prepare to compare versions (as they are sorted by everything else we can compare directly)
  intermittent_failures <- rep(FALSE, length(dependencies))
  names(intermittent_failures) <- names(dependencies)
  dep_0 <- lengths(dependencies) == 0
  intermittent_failures[dep_0] <- TRUE
```

If they do not have any recursive dependency on Depends, Imports, LinkingTo and Suggests they might be have some intermittent problems on the packages. 
These is only on dependencies on CRAN and Bioconductor but not in other additional repositories (There are `r sum(!is.na(ap[, "Additional_repositories"]))` packages with additional repositories). 

If they have some dependencies and those dependencies didn't change as far as we can tell then there might be some problems with random numbers or connectivity.

```{r intermittent-failures, eval=length(unique(possible_packages$Package)) < 1000}
for (pkg in names(intermittent_failures[!intermittent_failures])) {
  dep <- dependencies[[pkg]]
  fl <- possible_packages$Flavor[possible_packages$Package == pkg]
  intermittent_failures[pkg] <- all_checks |> 
    filter(Package %in% dep,
           Flavor %in% fl,
           Version.t == Version.y,
           Status.t != Status.y) |> 
    nrow() == 0 # If packages outside || any(!dep %in% rownames(ap)) 
}
packages <- names(intermittent_failures)[intermittent_failures]
```

We finally show the differences on the status of those without any dependency change on version or status^[I think a new version might not propagate to check other packages until 24 hours later as checks might have already started for that day.]:

```{r filter-packages, eval=length(unique(possible_packages$Package)) < 1000}
keep_files <- filter(possible_packages, Package %in% packages) |> 
  merge(y = flavors_df, by.x = "Flavor", by.y = "flavors", all.x = TRUE, all.y = FALSE) |> 
  select(Package, Flavor, Version = Version.t, R_version = r_version, OS = os, 
         architecture, other, version, revision) |> 
  mutate(Date = Sys.time())

if (nrow(keep_files >= 1)) {
  write.csv(keep_files, 
            paste0("cran-failing-", format(Sys.time(), "%Y%m%dT%H%M"), ".csv"),
            row.names = FALSE,
            quote = FALSE,
  )
}
```

```{r table-failures, eval=keep_files >= 1}
filter(possible_packages, Package %in% packages) |> 
  select(Package, Flavor, Today, Yesterday, -Version.t, -Version.y) |> 
  flextable() |> 
  autofit()
```

# Conclusion

```{r table-failures, eval=keep_files == 0, results="asis"}
cat("There are no packages detected with differences between yesterday and today attributable to intermittent failures.\n")
knitr::knit_exit()
```

```{r results='asis', eval=length(packages) > 0}
cat("This suggests that these packages might have some problems with random numbers or connectivity:\n\n") 
if (any(dep_0)) {
  cat("\n## Packages with dependencies\n\n")
  cat(paste0(" - ", sort(intersect(packages, 
                                   names(dependencies)[dep_0])), "\n"), sep = "")
  cat("\n## Packages without dependencies\n\n")
  cat(paste0(" - ", sort(intersect(packages,
                                   names(dependencies)[!dep_0])), "\n"), sep = "")
  
} else {
  cat(paste0(" - ", sort(packages), "\n"), sep = "")
}
```
